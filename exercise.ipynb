{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Arctop's Data Scientist Interview Exercise\n",
    "\n",
    "### In participating you understand and agree to the following:\n",
    "  \n",
    "  * The exercise is expected to take between 2-4 hours total.\n",
    "  * Arctop shall own all right, title and interest (including patent rights, copyrights, trade secret rights, mask work rights, sui generis database rights and all other intellectual property rights of any sort throughout the world) relating to any and all inventions (whether or not patentable), works of authorship, mask works, designs, know-how, ideas and information made or conceived or reduced to practice, in whole or in part, by you while working on this assignment.\n",
    "  \n",
    "  To memorialize your understanding and acceptance of the above, please type your name here ____________.\n",
    "\n",
    "### The challenge:\n",
    "\n",
    "The dataset (`data.txt`) consist of a 254,448 X 6 matrix containing a little over 8 minutes of 5-channel EEG data (sampled @ 512Hz). Columns 1-5 contain time-series voltage values, column 6 contains labels. The challenge is to distinguish label ‘1’ and ‘2’ given 5-channel EEG data alone.\n",
    "\n",
    " \n",
    "### Step-wise instructions:\n",
    "\n",
    "  1. **Denoise**  \n",
    "  EEG data is corrupted in many ways, by both natural and artificial sources. Design and implement a noise removal strategy for excluding all non-brain data and cleaning the signal.\n",
    "  2. **Feature extract**  \n",
    "  Extract discriminative features from the denoised data. Visualize them in some way.\n",
    "  3. **Classify**  \n",
    "  Design, implement and test a decision system that receives unlabeled, 5-channel EEG data and marks the occurence of events '1' and '2.' Report your system’s performance and predict how it will perform on future unseen data.\n",
    "  4. **Short synopsis**  \n",
    "  Summarize your approach to denoising, feature extraction, and classification. Discuss the results obtained and your ideas for next steps.\n",
    "\n",
    "### Files in this project\n",
    "\n",
    "  1. exercise.ipynb - this notebook\n",
    "  2. data.txt - the dataset\n",
    "  3. data_example.txt - first 500 lines of data.txt, a small sample to play with (if needed)\n",
    "  \n",
    "*** In the following cell you can find some general toy snippets. You can add cells to this notebook or, if you prefer, start a new one. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.6177807   0.79173285 -2.43172    -3.5369933   1.8705534   2.        ]\n",
      " [-6.7407338   1.9220913  -0.50380555 -1.8064288   3.2022301   2.        ]\n",
      " [-4.3723439   3.0359851   1.659851    0.01587108  4.6131257   2.        ]\n",
      " ..., \n",
      " [-4.7496488  -6.2221803  -6.1045638  -3.5615099   0.23952733  0.        ]\n",
      " [-4.1722077  -6.0872044  -6.0022555  -3.7184449  -0.06783045  0.        ]\n",
      " [-3.8255549  -5.9495871  -6.1235887  -4.1324408  -0.41764018  0.        ]]\n",
      "(500, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#data = np.loadtxt(\"data.txt\")\n",
    "example_data = np.loadtxt(\"data_example.txt\")\n",
    "\n",
    "print(example_data)\n",
    "print(example_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
